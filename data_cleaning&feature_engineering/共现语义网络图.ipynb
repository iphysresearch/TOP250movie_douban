{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076b99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../case_data/comment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9642d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import jieba \n",
    "import jieba.posseg as pseg\n",
    "def my_cut(text): \n",
    "    \n",
    "#     word_dict_file = './sport_word.dict'\n",
    "#     # 加载自定义词典\n",
    "#     jieba.load_userdict(word_dict_file)\n",
    " \n",
    "        \n",
    "    # 加载停用词\n",
    "    stop_words = [] \n",
    "    with open(\"../stopwords.txt\", encoding='utf-8') as f:\n",
    "       lines = f.readlines()\n",
    "       for line in lines:\n",
    "           stop_words.append(line.strip())\n",
    "    # stop_words[:10]\n",
    "           \n",
    "    return [w for w,flag in pseg.cut(text) if w not in stop_words and flag in ['n']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04306577",
   "metadata": {},
   "source": [
    "# 字符串存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44015f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2csv(filePath, s, x):\n",
    "    '''\n",
    "    将字符串写入到本地csv文件中\n",
    "    :param filePath: csv文件路径\n",
    "    :param s: 待写入字符串(逗号分隔格式)\n",
    "    '''\n",
    "    if x=='node':\n",
    "        with open(filePath, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Label,Weight\\r\")\n",
    "            f.write(s)\n",
    "        print('写入文件成功,请在'+filePath+'中查看')\n",
    "    else:\n",
    "        with open(filePath, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Source,Target,Weight\\r\")\n",
    "            f.write(s)\n",
    "        print('写入文件成功,请在'+filePath+'中查看')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2172402",
   "metadata": {},
   "source": [
    "## 构建字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496b915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDictValue(dict, is_reverse):\n",
    "    '''\n",
    "    将字典按照value排序\n",
    "    :param dict: 待排序的字典\n",
    "    :param is_reverse: 是否按照倒序排序\n",
    "    :return s: 符合csv逗号分隔格式的字符串\n",
    "    '''\n",
    "    # 对字典的值进行倒序排序,items()将字典的每个键值对转化为一个元组,key输入的是函数,item[1]表示元组的第二个元素,reverse为真表示倒序\n",
    "    tups = sorted(dict.items(), key=lambda item: item[1], reverse=is_reverse)\n",
    "    s = ''\n",
    "    for tup in tups:  # 合并成csv需要的逗号分隔格式\n",
    "        s = s + tup[0] + ',' + str(tup[1]) + '\\n'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0063d",
   "metadata": {},
   "source": [
    "## 构建共现矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951c90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(co_authors_list, is_reverse):\n",
    "    '''\n",
    "    根据共同列表,构建共现矩阵(存储到字典中),并将该字典按照权值排序\n",
    "    :param co_authors_list: 共同列表\n",
    "    :param is_reverse: 排序是否倒序\n",
    "    :return node_str: 三元组形式的节点字符串(且符合csv逗号分隔格式)\n",
    "    :return edge_str: 三元组形式的边字符串(且符合csv逗号分隔格式)\n",
    "    '''\n",
    "    node_dict = {}  # 节点字典,包含节点名+节点权值(频数)\n",
    "    edge_dict = {}  # 边字典,包含起点+目标点+边权值(频数)\n",
    "    # 第1层循环,遍历整表的每行信息\n",
    "    for row_authors in co_authors_list:\n",
    "        row_authors_list = row_authors.split(' ') # 依据','分割每行,存储到列表中\n",
    "        # 第2层循环\n",
    "        for index, pre_au in enumerate(row_authors_list): # 使用enumerate()以获取遍历次数index\n",
    "            # 统计单个词出现的频次\n",
    "            if pre_au not in node_dict:\n",
    "                node_dict[pre_au] = 1\n",
    "            else:\n",
    "                node_dict[pre_au] += 1\n",
    "            # 若遍历到倒数第一个元素,则无需记录关系,结束循环即可\n",
    "            if pre_au == row_authors_list[-1]:\n",
    "                break\n",
    "            connect_list = row_authors_list[index+1:]\n",
    "            # 第3层循环,遍历当前行词后面所有的词,以统计两两词出现的频次\n",
    "            for next_au in connect_list:\n",
    "                A, B = pre_au, next_au\n",
    "                # 固定两两词的顺序\n",
    "                # 仅计算上半个矩阵\n",
    "                if A==B:\n",
    "                    continue\n",
    "                if A > B:\n",
    "                    A, B = B, A\n",
    "                key = A+','+B  # 格式化为逗号分隔A,B形式,作为字典的键\n",
    "                # 若该关系不在字典中,则初始化为1,表示词间的共同出现次数\n",
    "                if key not in edge_dict:\n",
    "                    edge_dict[key] = 1\n",
    "                else:\n",
    "                    edge_dict[key] += 1\n",
    "    # 对得到的字典按照value进行排序\n",
    "    node_str = sortDictValue(node_dict, is_reverse)  # 节点\n",
    "    edge_str = sortDictValue(edge_dict, is_reverse)   # 边\n",
    "    return node_str, edge_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "696876c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "写入文件成功,请在./data/node.csv中查看\n",
      "写入文件成功,请在./data/edge.csv中查看\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "# os.chdir(r'.\\')#os.chdir() 方法用于改变当前工作目录到指定的路径\n",
    "filePath1 = r'./data/node.csv'\n",
    "filePath2 = r'./data/edge.csv'\n",
    "# 读取csv文件获取数据并存储到列表中\n",
    "df = pd.read_csv('../case_data/comment.csv',encoding='utf-8')\n",
    "co_ist = pd.read_csv('./data/words.csv')\n",
    "# co_ist = co_ist.values\n",
    "b = co_ist.values\n",
    "co_ist = list(chain.from_iterable(b))\n",
    "\n",
    "# df_ = df['content'][:100]\n",
    "# co_ist = [ \" \".join(my_cut(str(w))) for w in df_ if len(w)>0] \n",
    "# print(co_ist)\n",
    "# 根据共同词列表, 构建共现矩阵(存储到字典中), 并将该字典按照权值排序\n",
    "node_str, edge_str = build_matrix(co_ist, is_reverse=True)\n",
    "#print(edge_str)\n",
    "# 将字符串写入到本地csv文件中\n",
    "str2csv(filePath1,node_str,'node')\n",
    "str2csv(filePath2,edge_str,'edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0c6e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../case_data/comment.csv',encoding='utf-8')\n",
    "# df_ = df['content']\n",
    "# co_ist = [\" \".join(my_cut(str(w))) for w in df_] \n",
    "# co_ist = [item for item in co_ist if len(item)>0]\n",
    "# df2 = pd.DataFrame(co_ist)\n",
    "# df2.to_csv('./data/words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8b9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "edge_str = pd.read_csv('./data/edge.csv',encoding='utf-8')\n",
    "edge_str.shape\n",
    " \n",
    "edge_str1 = edge_str[edge_str['Weight']>300]\n",
    "edge_str1.shape\n",
    " \n",
    "Source = edge_str1['Source'].tolist()\n",
    "Target = edge_str1['Target'].tolist()\n",
    "co = Source + Target\n",
    "co =list(set(co))\n",
    " \n",
    "node_str = pd.read_csv('./data/node.csv',encoding='utf-8')\n",
    "#node_str\n",
    " \n",
    "node_str=node_str[node_str['Label'].isin(co)]\n",
    "node_str['id']=node_str['Label']\n",
    "node_str = node_str[['id','Label','Weight']] # 调整列顺序\n",
    "#node_str\n",
    " \n",
    "node_str.to_csv(path_or_buf=\"./data/node300.csv\", index=False) # 写入csv文件\n",
    "edge_str1.to_csv(path_or_buf=\"./data/edge300.csv\", index=False) # 写入csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec1693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
